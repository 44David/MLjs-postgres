# To do 

- [ ] - Set up and pull ollama ML models 
- [ ] - Make UI for chat interface 
- [ ] - Ability to select between ollama models

## Reminder
use wsl and ```ollama serve``` to start ollama 