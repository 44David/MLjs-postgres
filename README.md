# To do 

- [x] - Set up and pull ollama ML models 
- [x] - Make UI for chat interface 
- [ ] - Ability to select between ollama models, send requests to API and start instance
- [ ] - Set up ml models in the cloud for easy access


## Reminder
use wsl and ```ollama serve``` to start ollama 